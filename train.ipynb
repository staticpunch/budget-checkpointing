{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9194d411-9ec2-4058-a33e-aa7c1df7fb77",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cc91ba7-9a3a-42ac-bea6-4f65c9f22028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "bs27 = load_dataset(\"bespokelabs/Bespoke-Stratos-17k\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88675477-5dff-4751-9cdd-63ffdc57a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, example in enumerate(bs27):\n",
    "    assert len(example[\"conversations\"]) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "276f4851-b21b-473b-9e7c-6bb56d28a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_tag_content(text, begin=\"BEGIN\", end=\"END\"):\n",
    "    pattern = f\"{re.escape(begin)}(.*?){re.escape(end)}\"\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    return matches\n",
    "\n",
    "def restructure(example):\n",
    "    user, assistant = example.get(\"conversations\")\n",
    "    prompt, response = user[\"value\"], assistant[\"value\"]\n",
    "    thought = extract_tag_content(response, begin=\"<|begin_of_thought|>\", end=\"<|end_of_thought|>\")\n",
    "    solution = extract_tag_content(response, begin=\"<|begin_of_solution|>\", end=\"<|end_of_solution|>\")\n",
    "    return dict(\n",
    "        thought=thought[0].strip(),\n",
    "        solution=solution[0].strip()\n",
    "    )\n",
    "\n",
    "role_mapping = {\n",
    "    \"human\": \"user\",\n",
    "    \"user\": \"user\", \n",
    "    \"gpt\": \"assistant\",\n",
    "    \"assistant\": \"assistant\",\n",
    "    \"system\": \"system\"\n",
    "}\n",
    "\n",
    "def convert_example(example):\n",
    "    messages = []\n",
    "    for conv in example[\"conversations\"]:\n",
    "        messages.append({\n",
    "            \"role\": role_mapping.get(conv[\"from\"], conv[\"from\"]),\n",
    "            \"content\": conv[\"value\"]\n",
    "        })\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa72c635-a540-4f70-b478-12de3f1393e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bs27.map(restructure).filter(lambda x: len(x[\"thought\"].split()) < 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20c64282-408c-4f70-956b-6cbe327370a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(convert_example, remove_columns=[\"conversations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "36995a49-4edd-47d4-b132-430ffd27c979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's try to figure out this problem step by step. So, Marika's 8th birthday was in 2004. That means she was born in 2004 minus 8 years, which is 1996. Wait, no, actually, if her 8th birthday is in 2004, she was born in 1996 because 2004 minus 8 equals 1996. Yeah, that makes sense. So Marika was born in 1996.\n",
      "\n",
      "Now, in 2004, her father said, \"My age is now four times your age.\" So at that time, Marika is 8, so her father is 4 times 8, which is 32 years old. Wait, hold on. If the father is 32 years old in 2004, then he was born in 2004 minus 32, which is 1972. So the father's birth year is 1972. Let me check that again. If in 2004 the father is 32, then yes, 2004 - 32 = 1972. So father is born in 1972, Marika in 1996. So the age difference between them is 32 - 8 = 24 years. Wait, no, actually, the age difference is always constant. So if the father is 32 when Marika is 8, then the difference is 32 - 8 = 24 years. So the father is 24 years older than Marika. That makes sense.\n",
      "\n",
      "So the question is: In what year will Marika's father be able to say, \"My age is now three times your age,\" on Marika's birthday?\n",
      "\n",
      "So we need to find a future year where the father's age is three times Marika's age. Let's denote the number of years after 2004 when this will happen as x. So in the year 2004 + x, Marika's age will be 8 + x, and her father's age will be 32 + x. We need to find x such that:\n",
      "\n",
      "32 + x = 3 * (8 + x)\n",
      "\n",
      "Let me solve this equation step by step. Expanding the right side:\n",
      "\n",
      "32 + x = 24 + 3x\n",
      "\n",
      "Subtract 24 from both sides:\n",
      "\n",
      "8 + x = 3x\n",
      "\n",
      "Subtract x from both sides:\n",
      "\n",
      "8 = 2x\n",
      "\n",
      "Divide both sides by 2:\n",
      "\n",
      "x = 4\n",
      "\n",
      "Wait, so x is 4 years. So 2004 + 4 = 2008. So in 2008, the father would be 32 + 4 = 36, and Marika would be 8 + 4 = 12. 36 is three times 12. That checks out. But wait, hold on. The problem says \"In what year will Marika's father be able to say...\" So according to this, the answer would be 2008. But wait, that seems too straightforward. Let me verify again.\n",
      "\n",
      "Wait, maybe I made a mistake in setting up the equation. Let's see. Let me think differently. Let's denote t as the number of years after 2004 when the father's age is three times Marika's age. Then, in the year 2004 + t, Marika's age is 8 + t, and her father's age is 32 + t. The equation is 32 + t = 3*(8 + t). Solving that:\n",
      "\n",
      "32 + t = 24 + 3t\n",
      "\n",
      "Subtract 24:\n",
      "\n",
      "8 + t = 3t\n",
      "\n",
      "Subtract t:\n",
      "\n",
      "8 = 2t\n",
      "\n",
      "t = 4. So yes, t is 4 years after 2004, so 2008. So that seems correct. But let me check if that's possible. In 2008, Marika is 12, father is 36. 36 divided by 12 is 3. So that's correct. But wait, the father was 32 in 2004, so he was born in 1972. In 2008, he is 36, which is 2008 - 1972 = 36. Correct. Marika was born in 1996, so 2008 - 1996 = 12. Correct. So yes, 2008 is the year. So the answer should be 2008.\n",
      "\n",
      "But wait, the problem is presented in a way that suggests maybe the answer is not so straightforward. Let me think again. Wait, is there a possibility that the answer is later than 2008? Because sometimes age problems can have multiple solutions, but in this case, since the age ratio is decreasing over time, once the father's age is three times Marika's, it might not happen again. Wait, let's see. Let's check if there's another time when the father's age is three times Marika's.\n",
      "\n",
      "Suppose we set up the equation again. Let's say x years after 2004, father's age is 32 + x, Marika's age is 8 + x. So 32 + x = 3*(8 + x). As we saw, x = 4. If we check x = -4, that would be 2000, but Marika would be 4, father would be 28. 28 is 7 times 4, which is correct. But that's in the past, so the future solution is 2008.\n",
      "\n",
      "But maybe there's a trick here. Let me check the age difference. The father is 24 years older than Marika. So in any year, the age difference remains 24 years. So when will the father's age be three times Marika's age? Let's denote Marika's age at that time as M. Then father's age is M + 24. So we have M + 24 = 3*M. Solving:\n",
      "\n",
      "24 = 2M\n",
      "\n",
      "M = 12.\n",
      "\n",
      "So when Marika is 12, her father is 36, which is three times her age. So Marika was born in 1996, so when she is 12, the year is 1996 + 12 = 2008. So that's consistent with the previous result. So 2008 is the answer. Therefore, the answer should be 2008.\n",
      "\n",
      "Wait, but why did I initially think the problem might be trickier? Maybe because sometimes in age problems, people make mistakes with the birth years or the differences. Let me confirm once again.\n",
      "\n",
      "Marika's birth year: 2004 - 8 = 1996.\n",
      "\n",
      "Father's birth year: 2004 - (4*8) = 2004 - 32 = 1972.\n",
      "\n",
      "Age difference: 1972 - 1996 = -24, so father is 24 years older.\n",
      "\n",
      "So in year Y, Marika's age is Y - 1996, father's age is Y - 1972.\n",
      "\n",
      "We need Y - 1972 = 3*(Y - 1996)\n",
      "\n",
      "Solve:\n",
      "\n",
      "Y - 1972 = 3Y - 5988\n",
      "\n",
      "Bring variables to one side:\n",
      "\n",
      "-1972 + 5988 = 3Y - Y\n",
      "\n",
      "4016 = 2Y\n",
      "\n",
      "Y = 4016 / 2 = 2008.\n",
      "\n",
      "Yes, exactly. So 2008 is the correct year. So all methods lead to 2008. Therefore, the answer is 2008. I think that's solid.\n"
     ]
    }
   ],
   "source": [
    "print(data.shuffle()[0][\"thought\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8249f348-6933-442d-9b0c-29b333a6897f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To determine the time 2011 minutes after midnight on January 1, 2011, we first convert minutes into hours and days:\\n\\n1. **Convert 2011 minutes to hours**:  \\n   \\\\[\\n   2011 \\\\div 60 = 33 \\\\text{ hours and } 31 \\\\text{ minutes.}\\n   \\\\]  \\n   This means 2011 minutes is equivalent to 33 hours and 31 minutes.\\n\\n2. **Break down 33 hours into days and hours**:  \\n   \\\\[\\n   33 \\\\text{ hours} = 24 \\\\text{ hours (1 day)} + 9 \\\\text{ hours.}\\n   \\\\]  \\n   Adding 24 hours to midnight brings us to midnight on January 2. The remaining 9 hours and 31 minutes are then added to this time.\\n\\n3. **Calculate the final time**:  \\n   Starting from midnight on January 2, adding 9 hours gives 9:00 AM. Adding the remaining 31 minutes results in **9:31 AM**.\\n\\nThus, 2011 minutes after midnight on January 1, 2011, is **January 2 at 9:31 AM**.\\n\\n\\\\[\\n\\\\boxed{D}\\n\\\\]'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[32]['solution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3845653-a7d7-4920-992a-cbd85f19f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "def analyze_string_lengths(string_list):\n",
    "    \"\"\"\n",
    "    Calculate statistics about the lengths of strings in a list and plot distributions.\n",
    "    \n",
    "    Args:\n",
    "        string_list (list): A list of strings to analyze\n",
    "    \"\"\"\n",
    "    # Calculate lengths of each string\n",
    "    lengths = [len(s.split()) for s in string_list]\n",
    "    \n",
    "    # Basic statistics\n",
    "    stats_summary = {\n",
    "        \"Count\": len(lengths),\n",
    "        \"Min Length\": min(lengths),\n",
    "        \"Max Length\": max(lengths),\n",
    "        \"Average Length\": np.mean(lengths),\n",
    "        \"Median Length\": np.median(lengths),\n",
    "        \"Std Dev\": np.std(lengths),\n",
    "        \"25th Percentile\": np.percentile(lengths, 25),\n",
    "        \"75th Percentile\": np.percentile(lengths, 75)\n",
    "    }\n",
    "    \n",
    "    # Print statistics summary\n",
    "    print(\"String Length Statistics:\")\n",
    "    for stat, value in stats_summary.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"{stat}: {value:.2f}\")\n",
    "        else:\n",
    "            print(f\"{stat}: {value}\")\n",
    "    \n",
    "    # Create a figure with multiple plots\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 1. Histogram of string lengths\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.title('Distribution of String Lengths')\n",
    "    plt.xlabel('Length')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return the statistics dict in case it's needed\n",
    "    return stats_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0db27887-257a-4dec-8bd7-1827e443207c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String Length Statistics:\n",
      "Count: 11895\n",
      "Min Length: 141\n",
      "Max Length: 2999\n",
      "Average Length: 1258.47\n",
      "Median Length: 1058.00\n",
      "Std Dev: 679.60\n",
      "25th Percentile: 714.00\n",
      "75th Percentile: 1690.50\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Count': 11895,\n",
       " 'Min Length': 141,\n",
       " 'Max Length': 2999,\n",
       " 'Average Length': 1258.4741488020177,\n",
       " 'Median Length': 1058.0,\n",
       " 'Std Dev': 679.5954320206005,\n",
       " '25th Percentile': 714.0,\n",
       " '75th Percentile': 1690.5}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_string_lengths(\n",
    "    data[\"thought\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9ceba51-e5f2-49de-ad88-ceea2062db2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Return your final response within \\\\boxed{}. The operation $\\\\otimes$ is defined for all nonzero numbers by $a\\\\otimes b =\\\\frac{a^{2}}{b}$. Determine $[(1\\\\otimes 2)\\\\otimes 3]-[1\\\\otimes (2\\\\otimes 3)]$.\\n$\\\\text{(A)}\\\\ -\\\\frac{2}{3}\\\\qquad\\\\text{(B)}\\\\ -\\\\frac{1}{4}\\\\qquad\\\\text{(C)}\\\\ 0\\\\qquad\\\\text{(D)}\\\\ \\\\frac{1}{4}\\\\qquad\\\\text{(E)}\\\\ \\\\frac{2}{3}$',\n",
       "  'role': 'user'},\n",
       " {'content': \"<|begin_of_thought|>\\n\\nOkay, let me try to figure out this problem. So, we have this operation defined as a⊗b = a²/b. And we need to compute [(1⊗2)⊗3] - [1⊗(2⊗3)]. Then choose the correct answer from the options given. Alright, let's break it down step by step.\\n\\nFirst, I need to remember that the operation ⊗ is not associative, right? Because the problem is asking for the difference between two different groupings: (1⊗2)⊗3 and 1⊗(2⊗3). So, the order in which we perform the operations matters here. That's probably why there's a subtraction between them.\\n\\nLet me start by computing each part separately. Let's tackle the first part: (1⊗2)⊗3.\\n\\nStarting with the innermost operation, which is 1⊗2. According to the definition, a⊗b = a²/b. So here, a is 1 and b is 2. Plugging those in: 1² / 2 = 1/2. So, 1⊗2 equals 1/2.\\n\\nNow, we take that result and perform the next operation with 3. So, (1⊗2)⊗3 becomes (1/2)⊗3. Again, using the same definition: a is now 1/2 and b is 3. So, ( (1/2)² ) / 3 = (1/4) / 3 = 1/12. So, (1⊗2)⊗3 equals 1/12.\\n\\nAlright, that's the first part. Now let's compute the second part: 1⊗(2⊗3). Again, starting with the innermost operation, which is 2⊗3. Applying the definition: a is 2 and b is 3. So, 2² / 3 = 4/3. Therefore, 2⊗3 equals 4/3.\\n\\nNow, we need to compute 1⊗(4/3). Here, a is 1 and b is 4/3. Using the operation definition: 1² / (4/3) = 1 / (4/3) = 3/4. So, 1⊗(2⊗3) equals 3/4.\\n\\nNow, the problem asks for the difference between the two results: [(1⊗2)⊗3] - [1⊗(2⊗3)] = (1/12) - (3/4). To subtract these fractions, they need a common denominator. The denominators are 12 and 4, so 12 is the common denominator.\\n\\nConverting 3/4 to twelfths: 3/4 = 9/12. So, 1/12 - 9/12 = (1 - 9)/12 = -8/12. Simplifying that fraction by dividing numerator and denominator by 4: -8/12 = -2/3.\\n\\nHmm, looking at the answer choices, option A is -2/3. So, is that the answer? Wait, but let me double-check my calculations to make sure I didn't make a mistake somewhere.\\n\\nFirst, checking (1⊗2): 1² / 2 = 1/2. Correct. Then, (1/2)⊗3: (1/2)² / 3 = (1/4)/3 = 1/12. That seems right.\\n\\nNow, for 2⊗3: 2² / 3 = 4/3. Correct. Then, 1⊗(4/3): 1² / (4/3) = 1 / (4/3) = 3/4. Yes, that's correct.\\n\\nSubtracting 3/4 from 1/12: 1/12 - 3/4. Convert 3/4 to 9/12, so 1/12 - 9/12 = -8/12 = -2/3. Yes, that all checks out. So the answer should be -2/3, which is option A.\\n\\nWait, but let me think again. The operation is defined for all nonzero numbers, so we don't have any issues with division by zero here. 2⊗3 is 4/3, which is fine, and then 1⊗(4/3) is 3/4. Correct.\\n\\nAlternatively, maybe there's a different way to approach the problem? Let me try expanding both expressions using variables to see if there's a pattern.\\n\\nLet’s denote the first expression: (a⊗b)⊗c. Using the definition:\\n\\nFirst, compute a⊗b = a²/b.\\n\\nThen, take that result and ⊗ with c: (a²/b)⊗c = ( (a²/b)² ) / c = a⁴ / (b² c).\\n\\nNow, the second expression: a⊗(b⊗c). First compute b⊗c = b²/c.\\n\\nThen, a⊗(b²/c) = a² / (b²/c) = a² * (c / b²) = (a² c) / b².\\n\\nTherefore, the difference between the two expressions is:\\n\\n(a⁴ / (b² c)) - (a² c / b²) = (a⁴ - a² c²) / (b² c) = a² (a² - c²) / (b² c).\\n\\nHmm, factoring that, it's a² (a - c)(a + c) / (b² c).\\n\\nBut in our specific problem, a = 1, b = 2, c = 3. Plugging those values in:\\n\\n1² (1 - 3)(1 + 3) / (2² * 3) = 1 * (-2)(4) / (4 * 3) = (-8) / 12 = -2/3. Same result. So that confirms the answer is indeed -2/3.\\n\\nTherefore, I think my initial calculation was correct, and the answer is option A.\\n\\n**Final Answer**\\n\\\\boxed{A}\\n\\n<|end_of_thought|>\\n\\n<|begin_of_solution|>\\n\\nTo determine the value of \\\\([(1 \\\\otimes 2) \\\\otimes 3] - [1 \\\\otimes (2 \\\\otimes 3)]\\\\) where the operation \\\\(\\\\otimes\\\\) is defined by \\\\(a \\\\otimes b = \\\\frac{a^2}{b}\\\\), we proceed as follows:\\n\\nFirst, compute \\\\(1 \\\\otimes 2\\\\):\\n\\\\[\\n1 \\\\otimes 2 = \\\\frac{1^2}{2} = \\\\frac{1}{2}\\n\\\\]\\nNext, use this result to compute \\\\((1 \\\\otimes 2) \\\\otimes 3\\\\):\\n\\\\[\\n\\\\left(\\\\frac{1}{2}\\\\right) \\\\otimes 3 = \\\\frac{\\\\left(\\\\frac{1}{2}\\\\right)^2}{3} = \\\\frac{\\\\frac{1}{4}}{3} = \\\\frac{1}{12}\\n\\\\]\\n\\nNow, compute \\\\(2 \\\\otimes 3\\\\):\\n\\\\[\\n2 \\\\otimes 3 = \\\\frac{2^2}{3} = \\\\frac{4}{3}\\n\\\\]\\nThen, use this result to compute \\\\(1 \\\\otimes (2 \\\\otimes 3)\\\\):\\n\\\\[\\n1 \\\\otimes \\\\left(\\\\frac{4}{3}\\\\right) = \\\\frac{1^2}{\\\\frac{4}{3}} = \\\\frac{1}{\\\\frac{4}{3}} = \\\\frac{3}{4}\\n\\\\]\\n\\nFinally, find the difference between the two results:\\n\\\\[\\n\\\\frac{1}{12} - \\\\frac{3}{4} = \\\\frac{1}{12} - \\\\frac{9}{12} = \\\\frac{1 - 9}{12} = \\\\frac{-8}{12} = -\\\\frac{2}{3}\\n\\\\]\\n\\nThus, the answer is \\\\(\\\\boxed{A}\\\\).\\n\\n<|end_of_solution|>\",\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "46be7ac8-d020-4deb-811e-3e472f31983c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03f376e48d045208a30a9a25951d2a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "221266308"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to_json(\"../data/reasoning/mini-stratos-11k/train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "195ba2dd-0d60-4ba2-9e41-572b2346f46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c23d673ad346728a53108f42b19c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"../data/reasoning/mini-stratos-11k\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "205d2e9b-2de2-4986-9336-baa9adbdec10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['system', 'thought', 'solution', 'messages'],\n",
       "    num_rows: 11895\n",
       "})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443e8570-b637-4a7a-9987-d90b1f39b98e",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df4cd7d-ef0a-411a-b474-cd16ba364056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-24 11:25:59,310] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/opt/conda/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from models.llama import LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eba5bba-1eb4-4ee0-90f0-38d020617545",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"model_hub/Llama-3.2-1B-Instruct/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d298b918-7088-493c-bf92-e9d96ecc1055",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name\n",
    ")\n",
    "if not tokenizer.pad_token:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f39b3602-20f8-43b4-97c2-2bcfa6fd8815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AddedToken\n",
    "latent_tokens = [\n",
    "    AddedToken(f\"<|latent_{i:03}|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True)\n",
    "    for i in range(256)\n",
    "]\n",
    "\n",
    "markers = [\"<|begin_of_thought|>\", \"<|end_of_thought|>\", \"<|begin_of_solution|>\", \"<|end_of_solution|>\"]\n",
    "marker_tokens = [\n",
    "    AddedToken(marker, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True)\n",
    "    for marker in markers\n",
    "]\n",
    "\n",
    "new_tokens = latent_tokens + marker_tokens\n",
    "tokenizer.add_tokens(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc6e90f-1b3c-4b16-8092-4a2bfe612a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128512]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<|begin_of_thought|>\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd4e29f1-cbb2-4c42-b3f0-ef4a1fcd9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import (\n",
    "    Any, Callable, Dict, \n",
    "    List, NewType, Optional, \n",
    "    Tuple, Union, Mapping\n",
    ")\n",
    "from abc import ABC, abstractmethod\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from accelerate.logging import get_logger\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import safetensors\n",
    "import math\n",
    "import yaml\n",
    "import logging\n",
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    PreTrainedTokenizerBase,\n",
    "    PreTrainedModel,\n",
    "    PretrainedConfig,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    HfArgumentParser,\n",
    "    default_data_collator,\n",
    "    is_torch_xla_available,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(\n",
    "        self, tokenizer: PreTrainedTokenizerBase, \n",
    "        dataset_configs: Dict[str, int], \n",
    "        split: str, max_length: int, \n",
    "        train_on_inputs: bool = False\n",
    "    ):  # Add this parameter\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.dataset_configs = dataset_configs\n",
    "        self.split = split\n",
    "        self.max_length = max_length\n",
    "        self.train_on_inputs = train_on_inputs  # Store the flag\n",
    "\n",
    "    def load_dataset(self):\n",
    "        \"\"\"Load and prepare the training dataset.\"\"\"\n",
    "        datasets_list = []\n",
    "        \n",
    "        for data_config, num_samples in self.dataset_configs.items():\n",
    "            print(f\"Loading {num_samples} samples from {data_config}\")\n",
    "            new_dataset = load_dataset(data_config, split=self.split)\n",
    "            \n",
    "            # Randomly sample the specified number of examples\n",
    "            if num_samples and num_samples < len(new_dataset):\n",
    "                new_dataset = new_dataset.shuffle(seed=42).select(range(num_samples))\n",
    "\n",
    "            datasets_list.append(new_dataset)\n",
    "            \n",
    "        train_dataset = concatenate_datasets(datasets_list)\n",
    "        print(f\"Training on {len(train_dataset)} samples total.\")\n",
    "        return train_dataset.shuffle(seed=101)\n",
    "\n",
    "    def tokenize(self, element):\n",
    "        \"\"\"Tokenize a single element and mark tokens for loss computation based on train_on_inputs.\"\"\"\n",
    "        effective_spans = []\n",
    "        current_position = 0\n",
    "        \n",
    "        # Track positions of assistant messages\n",
    "        for message in element[\"messages\"]:\n",
    "            message_tokens = self.tokenizer.apply_chat_template(\n",
    "                [message],\n",
    "                tokenize=True,\n",
    "                add_generation_prompt=False\n",
    "            )\n",
    "            \n",
    "            if message[\"role\"] == \"assistant\" or (self.train_on_inputs and message[\"role\"] == \"user\"):\n",
    "                effective_spans.append((\n",
    "                    current_position,\n",
    "                    current_position + len(message_tokens)\n",
    "                ))\n",
    "            current_position += len(message_tokens)\n",
    "\n",
    "        # Tokenize full conversation\n",
    "        tokenized = self.tokenizer(\n",
    "            self.tokenizer.apply_chat_template(\n",
    "                element[\"messages\"],\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=False\n",
    "            ),\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            add_special_tokens=False\n",
    "        )\n",
    "\n",
    "        # Create labels with -100 for tokens we don't want to compute loss on\n",
    "        labels = [-100] * len(tokenized[\"input_ids\"])\n",
    "        for start, end in effective_spans:\n",
    "            for i in range(start, min(end, len(labels))):\n",
    "                labels[i] = tokenized[\"input_ids\"][i]\n",
    "                \n",
    "        tokenized[\"labels\"] = labels\n",
    "        return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95898cda-0562-4ae7-b7ef-49ca0bdef78f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'torch_default_data_collator' from 'transformers' (/opt/conda/lib/python3.11/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollatorForLanguageModeling, torch_default_data_collator\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'torch_default_data_collator' from 'transformers' (/opt/conda/lib/python3.11/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling, torch_default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df9e5c0b-e14f-4f34-9fb6-92d7aa587c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mdefault_data_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_collator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInputDataClass\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mdefault_data_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInputDataClass\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m    Very simple data collator that simply collates batches of dict-like objects and performs special handling for\u001b[0m\n",
       "\u001b[0;34m    potential keys named:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        - `label`: handles a single value (int or float) per object\u001b[0m\n",
       "\u001b[0;34m        - `label_ids`: handles a list of values per object\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Does not do any additional preprocessing: property names of the input object will be used as corresponding inputs\u001b[0m\n",
       "\u001b[0;34m    to the model. See glue and ner for example of how it's useful.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# In this function we'll make the assumption that all `features` in the batch\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# have the same attributes.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# So we will look at the first element as a proxy for what attributes exist\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# on the whole batch.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_default_data_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mtf_default_data_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"np\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy_default_data_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.11/site-packages/transformers/data/data_collator.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "default_data_collator??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b2f6ead-70f6-4067-84d7-9c7bab9cf9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass \n",
    "class SFTDataCollator:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    pad_to_multiple_of: Optional[int] = 4\n",
    "    return_tensors: str = \"pt\"\n",
    "    \n",
    "    def _format_batch_log(self, batch):\n",
    "        \"\"\"Format the batch sample log showing colored text chunks.\"\"\"\n",
    "        input_ids = batch[\"input_ids\"][0].tolist()  \n",
    "        labels = batch[\"labels\"][0].tolist()\n",
    "        \n",
    "        # Build chunks of tokens with same label type (-100 or non -100)\n",
    "        chunks = []\n",
    "        current_chunk = {\"tokens\": [], \"is_ignored\": labels[0] == -100}\n",
    "        \n",
    "        for token_id, label in zip(input_ids, labels):\n",
    "            is_ignored = label == -100\n",
    "            # If label type changes, start new chunk\n",
    "            if is_ignored != current_chunk[\"is_ignored\"]:\n",
    "                chunks.append(current_chunk)\n",
    "                current_chunk = {\"tokens\": [], \"is_ignored\": is_ignored}\n",
    "            current_chunk[\"tokens\"].append(token_id)\n",
    "        \n",
    "        # Add final chunk\n",
    "        chunks.append(current_chunk)\n",
    "        \n",
    "        # Format output\n",
    "        log_messages = []\n",
    "        log_messages.append(\"=== Sample text chunks ===\")\n",
    "        # Decode and display each chunk with appropriate color\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            text = self.tokenizer.decode(chunk[\"tokens\"])\n",
    "            color = (\"\\033[90m\" if (i == len(chunks) - 1) and chunk[\"is_ignored\"] # Gray for padded.\n",
    "                     else \"\\033[91m\" if chunk[\"is_ignored\"] # Red for ignored.\n",
    "                     else \"\\033[92m\") # Green for trained.\n",
    "            log_messages.append(f\"{color}{text}\\033[0m\")\n",
    "            \n",
    "        \n",
    "        log_messages.append(\"==========================\")\n",
    "        return \"\\n\".join(log_messages)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.first_batch = True\n",
    "\n",
    "    def __call__(self, examples: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"Process a batch with proper padding.\"\"\"\n",
    "        if not isinstance(examples[0], Mapping):\n",
    "            raise ValueError(\"Data collator only processes list of dictionaries.\")\n",
    "        \n",
    "        # Extract input_ids and labels\n",
    "        input_ids_list = []\n",
    "        labels_list = []\n",
    "        other_features = {}\n",
    "        \n",
    "        for example in examples:\n",
    "            # Pop attention_mask if present (not needed for padding)\n",
    "            example.pop(\"attention_mask\", None)\n",
    "            \n",
    "            # Extract input_ids and labels\n",
    "            input_ids_list.append({\"input_ids\": example.pop(\"input_ids\")})\n",
    "            labels_list.append({\"input_ids\": example.pop(\"labels\")})\n",
    "            \n",
    "            # Collect other features\n",
    "            for key, value in example.items():\n",
    "                if key not in other_features:\n",
    "                    other_features[key] = []\n",
    "                other_features[key].append(value)\n",
    "        \n",
    "        # Pad input_ids\n",
    "        batch = self.tokenizer.pad(\n",
    "            input_ids_list,\n",
    "            return_tensors=self.return_tensors,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            padding_side=\"right\",\n",
    "        )\n",
    "        \n",
    "        # Pad labels\n",
    "        labels_batch = self.tokenizer.pad(\n",
    "            labels_list,\n",
    "            return_tensors=self.return_tensors,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            padding_side=\"right\",\n",
    "        )\n",
    "        \n",
    "        # Set padded positions in labels to -100 (ignore in loss)\n",
    "        labels = labels_batch[\"input_ids\"]\n",
    "        if self.tokenizer.pad_token_id is not None:\n",
    "            labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "        batch[\"labels\"] = labels\n",
    "        \n",
    "        # Add other features to batch\n",
    "        for key, values in other_features.items():\n",
    "            if key in batch:\n",
    "                raise ValueError(\n",
    "                    f\"`{key}` feature is already collated. \"\n",
    "                    \"Overriding it with initial values is prohibited.\"\n",
    "                )\n",
    "            \n",
    "            # Convert to tensor if all values are numeric\n",
    "            if all(isinstance(v, (int, float)) for v in values):\n",
    "                batch[key] = torch.tensor(values, dtype=torch.long)\n",
    "            else:\n",
    "                batch[key] = values\n",
    "        \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b56e0ad5-af4b-4e83-a173-d7deef5af8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading None samples from /workspace/data/reasoning/mini-stratos-11k\n",
      "Training on 11895 samples total.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b794ce3c144553a537b22eedbf05ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/11895 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup tokenizer and data processing\n",
    "\n",
    "dataset_configs = {\n",
    "    \"/workspace/data/reasoning/mini-stratos-11k\": None\n",
    "}\n",
    "    \n",
    "data_processor = DataProcessor(\n",
    "    tokenizer, \n",
    "    dataset_configs, \n",
    "    split=\"train\", \n",
    "    max_length=4096, \n",
    "    train_on_inputs=True\n",
    ")\n",
    "train_dataset = data_processor.load_dataset()\n",
    "tokenized_dataset = train_dataset.map(\n",
    "    data_processor.tokenize,\n",
    "    # remove_columns=[\"messages\"],\n",
    "    num_proc=32\n",
    ").select_columns([\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf1099fa-3f69-4485-8cf2-bdf28a7ad730",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = SFTDataCollator(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76626bde-ef01-4e16-afc8-3b216af52bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 11895\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "656658ce-2a96-41c4-968b-656a8686b1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(128516, 2048, padding_idx=128004)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba5f11ab-47d8-4877-aeb8-eb589934f5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function transformers.loss.loss_utils.ForCausalLMLoss(logits, labels, vocab_size: int, num_items_in_batch: Optional[int] = None, ignore_index: int = -100, shift_labels: Optional[torch.Tensor] = None, **kwargs) -> torch.Tensor>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31b76e67-4b95-4659-be92-bd51dde9a43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.loss.loss_utils import ForCausalLMLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b770305-f8ff-48fa-9556-2a02cff1d97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mForCausalLMLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvocab_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mignore_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshift_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mForCausalLMLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvocab_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mignore_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshift_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Upcast to float if we need to compute the loss to avoid potential precision issues\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mshift_labels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Shift so that tokens < n predict n\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mshift_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Flatten the tokens\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshift_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshift_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Enable model parallelism\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshift_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshift_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfixed_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.11/site-packages/transformers/loss/loss_utils.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ForCausalLMLoss??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8f84f62f-08f9-45fc-9cc3-c0ac1a6975dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 11895\n",
       "})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e830cd8d-63cc-4ffd-a0fa-a0d2d75aa995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        How the loss is computed by Trainer. By default, all models return the loss in the first element.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Subclass and override for custom behavior.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_smoother\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"labels\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_accepts_loss_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mloss_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mloss_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpast_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_past\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpast_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0munwrapped_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0m_is_peft_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munwrapped_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrapped_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrapped_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# User-defined compute_loss function\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODEL_FOR_CAUSAL_LM_MAPPING_NAMES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_smoother\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_smoother\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"loss\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"The model did not return a loss from the inputs, only the following keys: \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"{','.join(outputs.keys())}. For reference, the inputs it received are {','.join(inputs.keys())}.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_tokens_across_devices\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_accepts_loss_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mand\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mloss\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_processes\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.11/site-packages/transformers/trainer.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Trainer.compute_loss??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8c13e14d-6e9c-43b8-88fb-c16c88ceefc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "collated = data_collator([tokenized_dataset[0]]).to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f304508e-2668-4afb-8c60-a2b2a792ec16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000, 128006,   9125,  ...,   2595, 128515, 128009]],\n",
       "       device='cuda:1'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:1'), 'labels': tensor([[128000, 128006,   9125,  ...,   2595, 128515, 128009]],\n",
       "       device='cuda:1')}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "66ab5f8c-165d-420f-8cf6-a664726ab1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "34305761-0601-4076-93ff-b22655057a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(**collated).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fef440d0-78c6-4cb1-9c1b-3b59b3feeb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.8281,  3.5625,  7.0000,  ...,  0.1494,  0.1504,  0.1504],\n",
       "         [-3.1406, -2.1250, -1.1562,  ...,  0.1533,  0.1533,  0.1533],\n",
       "         [ 3.4062,  6.0000,  4.1562,  ..., -1.3672, -1.3672, -1.3672],\n",
       "         ...,\n",
       "         [ 3.5781,  8.1250,  9.5625,  ...,  0.4902,  0.4902,  0.4902],\n",
       "         [ 1.2734,  7.6875,  7.2500,  ..., -1.9766, -1.9766, -1.9766],\n",
       "         [-4.9375, -0.3535, -0.1797,  ..., -1.4688, -1.4688, -1.4688]]],\n",
       "       device='cuda:1', dtype=torch.bfloat16, grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "afc1ffc8-d7ba-4d08-af8a-9b0c3b827b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import yaml\n",
    "import logging\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "class SFTTrainer(Trainer):\n",
    "    \"\"\"\n",
    "    Hello it's Nguyen Thanh Do.\n",
    "    \"\"\" \n",
    "    def log(self, logs: Dict[str, float], start_time: Optional[float] = None) -> None:\n",
    "        output = {**logs, **{\"step\": self.state.global_step}}\n",
    "        self.state.log_history.append(output)\n",
    "        self.control = self.callback_handler.on_log(self.args, self.state, self.control, logs)\n",
    "\n",
    "    def compute_entropy_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        # Get inputs\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        labels = inputs[\"labels\"]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=inputs.get(\"attention_mask\"))\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Shift logits and labels for causal LM\n",
    "        # logits: [batch_size, seq_len, vocab_size]\n",
    "        # We predict token i+1 from tokens 0:i\n",
    "        shift_logits = logits[..., :-1, :].contiguous()  # Remove last token\n",
    "        shift_labels = labels[..., 1:].contiguous()      # Remove first token\n",
    "        \n",
    "        # Flatten for cross entropy computation\n",
    "        shift_logits = shift_logits.view(-1, shift_logits.size(-1))  # [batch_size * (seq_len-1), vocab_size]\n",
    "        shift_labels = shift_labels.view(-1)                         # [batch_size * (seq_len-1)]\n",
    "        \n",
    "        # Compute cross entropy loss (ignore_index=-100 by default)\n",
    "        loss = F.cross_entropy(shift_logits, shift_labels, ignore_index=-100)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        ## Debug: Before computing loss.\n",
    "        # ------------------------------------------------------\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad and torch.isnan(param).any():\n",
    "                logger.info(f\"NaN detected in parameter {name}\")\n",
    "                import pdb; pdb.set_trace()\n",
    "        # ------------------------------------------------------\n",
    "        \n",
    "        loss_func = self.compute_entropy_loss\n",
    "        loss = loss_func(model, inputs, return_outputs, num_items_in_batch)\n",
    "            \n",
    "        ## Debug: After computing loss.\n",
    "        # ------------------------------------------------------\n",
    "        if torch.isnan(loss):\n",
    "            logger.info(f\"Loss became NaN\")\n",
    "            import pdb; pdb.set_trace()\n",
    "        # ------------------------------------------------------\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6c02a8e9-fd45-4149-ad27-4b20c78db1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.float16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
